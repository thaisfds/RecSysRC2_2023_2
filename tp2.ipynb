{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Milena e Thaís - Lightfm Recommender System"
      ],
      "metadata": {
        "id": "ULnmDyQBIDqK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTMRXBmWlDLV",
        "outputId": "b318616d-746f-4148-e636-d6b5ccddf42d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lightfm\n",
            "  Downloading lightfm-1.17.tar.gz (316 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/316.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/316.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.4/316.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lightfm) (1.23.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from lightfm) (1.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from lightfm) (2.31.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from lightfm) (1.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->lightfm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->lightfm) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->lightfm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->lightfm) (2023.7.22)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lightfm) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lightfm) (3.2.0)\n",
            "Building wheels for collected packages: lightfm\n"
          ]
        }
      ],
      "source": [
        "!pip install lightfm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWfXIhjKfdT6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from lightfm import LightFM\n",
        "import lightfm.cross_validation\n",
        "from lightfm.evaluation import precision_at_k\n",
        "from lightfm.data import Dataset\n",
        "import sys"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Leitura e Analise inicial dos Dados"
      ],
      "metadata": {
        "id": "-Bq1MtsRIIgu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0jqC7E_fdUD"
      },
      "outputs": [],
      "source": [
        "content = pd.read_json('/content/content.jsonl', lines=True).drop(columns=['Rated', 'Released', 'Writer', 'Plot', 'Poster', 'Ratings','DVD', 'Production', 'Website', 'Response', 'totalSeasons', 'Season', 'Episode', 'Episode', 'seriesID', 'Type', 'Runtime'])\n",
        "ratings = pd.read_json('/content/ratings.jsonl', lines=True).drop(columns=['Timestamp'])\n",
        "targets = pd.read_csv('/content/targets.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "content.columns #Listar todas as colunas de content"
      ],
      "metadata": {
        "id": "ODdtnZ3jIRKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Funções Auxiliáres"
      ],
      "metadata": {
        "id": "x8QZ3L-_ITgE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2foOOaGFfdUJ"
      },
      "outputs": [],
      "source": [
        "def generateGenres(content, column):\n",
        "    #Splitar o genero por , e Substituir ' ' por ''\n",
        "    genre = content[column].str.replace(' ','').str.split(',')\n",
        "\n",
        "    #Pega os generos unicos\n",
        "    uniqueGenres = set()\n",
        "    for i in genre:\n",
        "        for j in i:\n",
        "            uniqueGenres.add(j)\n",
        "\n",
        "    #Cria duas novas colunas para marcar se o conteudo tem ou nao o genero\n",
        "    features_vector = []\n",
        "\n",
        "    for g in uniqueGenres:\n",
        "        content[g] = content[column].apply(lambda y: g in y)\n",
        "        features_vector.append(g+':False')\n",
        "        features_vector.append(g+':True')\n",
        "\n",
        "\n",
        "    #Adapta as features par o lightfm\n",
        "    #Se um filme pertence aos gêneros “Ação” e “Aventura”, a lista de strings correspondente terá os elementos “Ação:True” e “Aventura:True”.\n",
        "\n",
        "    features_matrix = []\n",
        "\n",
        "    for i in content.to_dict(orient='Records'):\n",
        "        features_matrix.append([g+':'+str(i[g]) for g in uniqueGenres])\n",
        "\n",
        "\n",
        "    return features_vector, features_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_KhKxTKfdUL"
      },
      "outputs": [],
      "source": [
        "# Mudar o formato de coluna de string pra lista\n",
        "def filterColumn(item_features,column,prefix='g:'):\n",
        "    item_features[column] = item_features[column].str.replace(' ','').str.split(',')\n",
        "    unique = set()\n",
        "    for x in item_features[column]:\n",
        "        for j in x:\n",
        "            unique.add(j)\n",
        "    features=[]\n",
        "    for g in unique:\n",
        "        features.append(prefix+g)\n",
        "\n",
        "    return features,unique"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Gera as feats de lightfm para todos os itens\n",
        "def genColumn(item_features,column,prefix='g:'):\n",
        "    feat=[]\n",
        "    for x in item_features.to_dict(orient='Records'):\n",
        "        feat.append([prefix+str(g) for g in x[column]])\n",
        "    return feat"
      ],
      "metadata": {
        "id": "EXHrIo2JJ4Na"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rc4FbgJxfdUN"
      },
      "outputs": [],
      "source": [
        "#Transforma os valores pra int na forma de string\n",
        "def intOrNa(value):\n",
        "    value=value.replace(',','')\n",
        "    if value !='N/A':\n",
        "        return str(round(float(value)))\n",
        "    else:\n",
        "        return ''\n",
        "\n",
        "#Chama intOrNa para todos os valores\n",
        "def strToInt(item_features,column):\n",
        "    item_features[column] = item_features[column].apply(lambda rating: intOrNa(rating))\n",
        "    return [column+':'+str(rating) for rating in item_features[column].drop_duplicates().to_list()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzZNzbn5fdUO"
      },
      "outputs": [],
      "source": [
        "#Transforma coluna numerica em categórica\n",
        "def filterBig(df,column):\n",
        "    df.loc[df[column] > 10**5,column] = 10**5\n",
        "    df.loc[(df[column] < 10**5) &(df[column] > 10**4),column] = 10**4\n",
        "    df.loc[(df[column] < 10**4) &(df[column] > 10**3),column] = 10**3\n",
        "    df.loc[(df[column] < 10**3) &(df[column] > 10**2),column] = 10**2\n",
        "    df.loc[(df[column] < 10**2),column] = 10**1\n",
        "    df.loc[df[column].isna(),column] ='N/A'\n",
        "    df[column]=df[column].astype(str)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJ70ne6ZwBiv"
      },
      "outputs": [],
      "source": [
        "#Transforma awards (nominations / wins) em categorico\n",
        "def awardsFeats(item_features,column,prefix='n:'):\n",
        "    awards = item_features[column].copy()\n",
        "    awards[(awards>=1) & (awards<5)] = 1\n",
        "    awards[(awards>=5) & (awards<10)] = 5\n",
        "    awards[(awards>=10) & (awards<15)] = 10\n",
        "    awards[(awards>=15)] = 15\n",
        "    feats = [prefix+str(x) for x in awards]\n",
        "    features = [prefix+'0',prefix+'1',prefix+'5',prefix+'10',prefix+'15']\n",
        "    return features, feats"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Transforma coluna numerica em categórica para BigBoxOffice\n",
        "def filterBigBoxOffice(df,column):\n",
        "    df.loc[df[column] > 10**8,column] = 10**8\n",
        "    df.loc[(df[column] < 10**8) &(df[column] > 10**7),column] = 10**7\n",
        "    df.loc[(df[column] < 10**7) &(df[column] > 10**6),column] = 10**6\n",
        "    df.loc[(df[column] < 10**6) &(df[column] > 10**5),column] = 10**5\n",
        "    df.loc[(df[column] < 10**5) &(df[column] > 10**4),column] = 10**4\n",
        "    df.loc[(df[column] < 10**4) &(df[column] > 10**3),column] = 10**3\n",
        "    df.loc[(df[column] < 10**3) &(df[column] > 10**2),column] = 10**2\n",
        "    df.loc[(df[column] < 10**2),column] = 10**1\n",
        "    df.loc[df[column].isna(),column] ='N/A'\n",
        "    df[column]=df[column].astype(str)"
      ],
      "metadata": {
        "id": "7DiKdSv-Kz9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Limpeza dos dados de content\n",
        "\n",
        "Genre: Transformar os generos em colunas binárias\n",
        "\n",
        "Director: Transformar coluna de string pra lista\n",
        "\n",
        "Language: Ignorar linguas poucas conhecidas\n",
        "\n",
        "Awards: Separar nominations de wins\n",
        "\n",
        "Metascore: Transformar em int\n",
        "\n",
        "imdbRating: Transformar em int\n",
        "\n",
        "imdVotes: Transformar em int\n",
        "\n",
        "BoxOfficeOg:"
      ],
      "metadata": {
        "id": "8jcnJBw7JLsD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IY9Ier9CfdUP"
      },
      "outputs": [],
      "source": [
        "#Generate \"original version\" of some columns before turning them categorical\n",
        "#these will be used for cold start users as well as to give weight to popularity later\n",
        "content['imdbVotesOg'] = content['imdbVotes'].copy()\n",
        "content['imdbRatingOg'] = content['imdbRating'].copy()\n",
        "content['MetascoreOg'] = content['Metascore'].copy()\n",
        "content['BoxOfficeOg'] = content['BoxOffice'].copy()\n",
        "#convert votes to int\n",
        "strToInt(content,'imdbVotesOg')\n",
        "content['imdbVotesOg']=pd.to_numeric(content['imdbVotesOg'])\n",
        "\n",
        "#convert boxoffice to int\n",
        "content['BoxOfficeOg'] = content['BoxOfficeOg'].replace('[\\$,]', '', regex=True)\n",
        "content['BoxOfficeOg'] = pd.to_numeric(content['BoxOfficeOg'], errors='coerce', downcast='integer')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xI_hRvujfdUQ"
      },
      "outputs": [],
      "source": [
        "#Language features, filter languages that appear fewer than 200 times as other\n",
        "content['Language'] = content['Language'].apply(lambda x: x.split(',')[0].replace(' ',''))\n",
        "content.loc[content['Language']=='N/A', 'Language'] = \"None\"\n",
        "content.loc[content['Language'].value_counts()[content['Language']].values < 200, 'Language'] = \"Other\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#country features, filter countries that appear fewer than 200 times as other\n",
        "content['Country'] = content['Country'].apply(lambda x: x.split(',')[0].replace(' ',''))\n",
        "content.loc[content['Country']=='N/A', 'Country'] = \"None\"\n",
        "content.loc[content['Country'].value_counts()[content['Country']].values < 200, 'Country'] = \"Other\""
      ],
      "metadata": {
        "id": "_3NhHaS0JsPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#actors features,\n",
        "content['Actors'] = content['Actors'].apply(lambda x: x.split(',')[0].replace(' ',''))\n",
        "content.loc[content['Actors']=='N/A', 'Actors'] = \"None\"\n",
        "#content.loc[content['Actors'].value_counts()[content['Actors']].values < 1, 'Country'] = \"Other\""
      ],
      "metadata": {
        "id": "wSHeOj9SgfYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nK3AYC4AwOUV"
      },
      "outputs": [],
      "source": [
        "#generate nominations column (parse text on awards and transform to numeric)\n",
        "content['Nominations']=content['Awards'].str.findall(r'[0-9]+ nomination').str.join(\",\").str.replace(r'[a-zA-Z]+','',regex=True)\n",
        "content.loc[content['Nominations']=='','Nominations']=0\n",
        "content['Nominations']=pd.to_numeric(content['Nominations'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVOHbB6mwSTD"
      },
      "outputs": [],
      "source": [
        "#generate wins column (parse text on awards and transform to numeric), specific award wins not considered\n",
        "content['Wins']=content['Awards'].str.findall(r'[0-9]+ win').str.join(\",\").str.replace(r'[a-zA-Z]+','',regex=True)\n",
        "content.loc[content['Wins']=='','Wins']=0\n",
        "content['Wins']=pd.to_numeric(content['Wins'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPhD13kgfdUT"
      },
      "outputs": [],
      "source": [
        "#genre\n",
        "genre_features, genre_feat = generateGenres(content, 'Genre')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJx9b8jAxPky"
      },
      "outputs": [],
      "source": [
        "#awards\n",
        "wins_features,wins_feats = awardsFeats(content,'Wins','w:')\n",
        "nom_features,nom_feats = awardsFeats(content,'Nominations','n:')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFvY645ufdUV"
      },
      "outputs": [],
      "source": [
        "#director\n",
        "director_features,_ = filterColumn(content,'Director','dir:')\n",
        "dir_feat = genColumn(content,'Director','dir:')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3v5P44jEfdUX"
      },
      "outputs": [],
      "source": [
        "#rating features\n",
        "rating_features = strToInt(content,'imdbRating')\n",
        "metascore_features = strToInt(content,'Metascore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bk2yiyXIfdUZ"
      },
      "outputs": [],
      "source": [
        "#language\n",
        "language_features = list(content['Language'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#country\n",
        "country_features = list(content['Country'].unique())"
      ],
      "metadata": {
        "id": "1FZ8fg65K4et"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#actors\n",
        "#actors_features = list(content['Actors'].unique())"
      ],
      "metadata": {
        "id": "hoMB6rK-hLtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fy9dpMH-fdUa"
      },
      "outputs": [],
      "source": [
        "#votes\n",
        "_=strToInt(content,'imdbVotes')\n",
        "content['imdbVotes']=pd.to_numeric(content['imdbVotes'])\n",
        "filterBig(content,'imdbVotes')\n",
        "votes_features = strToInt(content,'imdbVotes')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#year\n",
        "#max_value = content['Year'].max()\n",
        "#min_value = content['Year'].min()\n",
        "\n",
        "#print(f\"Maximum value: {max_value}\")\n",
        "#print(f\"Minimum value: {min_value}\")"
      ],
      "metadata": {
        "id": "xHLYGF4z1Rm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#content['Year'] = content['Year'].str.extract('(\\d+)').astype(float)"
      ],
      "metadata": {
        "id": "LaJzDenn3ZTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#content['Year'] =  content['Year'].str.replace(r'\\D', '').astype(int)"
      ],
      "metadata": {
        "id": "JFi1HmBU75Hw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#year_features = ['year'+':'+str(rating) for rating in content['Year'].drop_duplicates().to_list()]"
      ],
      "metadata": {
        "id": "oBH3IQh61uyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#year_feats = feats = ['year'+':'+str(x) for x in content['Year']]"
      ],
      "metadata": {
        "id": "oQXnSLbm6Hkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uf8IwkCZ-rDN"
      },
      "outputs": [],
      "source": [
        "#convert boxoffice to int\n",
        "#content['BoxOffice'] = content['BoxOffice'].replace('[\\$,]', '', regex=True)\n",
        "#content['BoxOffice'] = pd.to_numeric(content['BoxOffice'], errors='coerce', downcast='integer')\n",
        "#filterBigBoxOffice(content,'BoxOffice')\n",
        "#box_features = ['BoxOffice'+':'+str(rating) for rating in content['BoxOffice'].drop_duplicates().to_list()]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBkGL6ACfdUb"
      },
      "outputs": [],
      "source": [
        "#Cria as features para cada item para o lightfm, feats comentadas pioraram o recomendador\n",
        "\n",
        "item_ids = content['ItemId'].to_list()\n",
        "feat = [(item_ids[i],g) for i,g in enumerate(genre_feat)]\n",
        "#feat= [(feat[i][0],feat[i][1]+dfeat) for i,dfeat in enumerate(dir_feat)]\n",
        "feat = [(feat[i][0],feat[i][1]+['imdbRating:'+j]) for i,j in enumerate(content['imdbRating'])]\n",
        "#feat = [(feat[i][0],feat[i][1]+['Metascore:'+j]) for i,j in enumerate(content['Metascore'])]\n",
        "feat = [(feat[i][0],feat[i][1]+['imdbVotes:'+j]) for i,j in enumerate(content['imdbVotes'])]\n",
        "#feat = [(feat[i][0],feat[i][1]+['BoxOffice:'+j]) for i,j in enumerate(content['BoxOffice'])]\n",
        "feat = [(feat[i][0],feat[i][1]+[w]) for i,w in enumerate(wins_feats)]\n",
        "feat = [(feat[i][0],feat[i][1]+[w]) for i,w in enumerate(nom_feats)]\n",
        "feat = [(feat[i][0],feat[i][1]+[w]) for i,w in enumerate(content['Language'])]\n",
        "feat = [(feat[i][0],feat[i][1]+[w]) for i,w in enumerate(content['Country'])]\n",
        "#feat = [(feat[i][0],feat[i][1]+[w]) for i,w in enumerate(year_feats)]\n",
        "#feat = [(feat[i][0],feat[i][1]+[w]) for i,w in enumerate(content['Actors'])]\n",
        "#feat = [(feat[i][0],feat[i][1]+[w]) for i,w in enumerate(content['Year'])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-nYfzyqfdUc"
      },
      "outputs": [],
      "source": [
        "#create list of possible features for lightfm\n",
        "#genre\n",
        "#director\n",
        "#ratings\n",
        "#votes\n",
        "#language\n",
        "#wins\n",
        "#nominations\n",
        "#countries\n",
        "\n",
        "#features = genre_features+director_features+rating_features+votes_features+language_features\n",
        "#features = genre_features+director_features+rating_features+metascore_features+votes_features+wins_features+language_features+box_features\n",
        "features = genre_features+rating_features+votes_features+wins_features+language_features+country_features+nom_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAhAOXG-fdUd"
      },
      "outputs": [],
      "source": [
        "# Contrução do lightfm dataset\n",
        "dataset = Dataset()\n",
        "dataset.fit((x for x in ratings['UserId'].to_list()),\n",
        "            (x for x in ratings['ItemId'].to_list()))\n",
        "num_users, num_items = dataset.interactions_shape()\n",
        "(interactions, weights) = dataset.build_interactions(((x['UserId'], x['ItemId'])\n",
        "                                                    for x in ratings.to_dict(orient='records')))\n",
        "dataset.fit_partial(items=(x for x in content['ItemId'].to_list()),\n",
        "        item_features=features)\n",
        "item_feat = dataset.build_item_features(feat)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jqQpUyTrfdUe"
      },
      "outputs": [],
      "source": [
        "#Treino do lightfm\n",
        "model = LightFM(loss='warp', random_state=3, max_sampled=5)\n",
        "model.fit(interactions, item_features=item_feat, epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SeS8n3_OfdUf"
      },
      "outputs": [],
      "source": [
        "#Preparo das previsões\n",
        "user_id_map, user_feature_map, item_id_map, item_feature_map =dataset.mapping()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUOnw0cYfdUg"
      },
      "outputs": [],
      "source": [
        "#Previsões de coldstart value (sort by benchmarks)\n",
        "def sort_by_features(df):\n",
        "    predictions = pd.merge(df,content,on='ItemId')\n",
        "    predictions.sort_values(by=['imdbVotesOg','Nominations','Wins','imdbRatingOg','ItemId'],ascending=[False,False,False,False,True],inplace=True)\n",
        "    return predictions[['UserId','ItemId']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxfGU8z2fdUh"
      },
      "outputs": [],
      "source": [
        "#Previsões com lightfm\n",
        "def sort_by_predictions(df):\n",
        "    #converter ID de usuários em mapeamento interno lightfm\n",
        "    users=df['UserId'].apply(lambda u:user_id_map[u]).values\n",
        "    items=df['ItemId'].apply(lambda i:item_id_map[i]).values\n",
        "\n",
        "    #prever pontuações\n",
        "    predictions=model.predict(users,items,item_features=item_feat)\n",
        "    df['Prediction']=predictions\n",
        "\n",
        "    #padronizar para permitir a combinação com item_features\n",
        "    df['Prediction'] = (df['Prediction']-df['Prediction'].mean())/df['Prediction'].std()\n",
        "\n",
        "    #atribua um peso à popularidade dos itens padronizados no dataset (já que os usuários parecem preferir itens populares)\n",
        "    df = pd.merge(df,content,on='ItemId')\n",
        "    df['Prediction'] +=0.25*(df['imdbVotesOg']-df['imdbVotesOg'].mean())/df['imdbVotesOg'].std()\n",
        "    #df['Prediction'] +=0.125*(df['BoxOfficeOg']-df['BoxOfficeOg'].mean())/df['BoxOfficeOg'].std()\n",
        "\n",
        "    #retornar previsões de user-item classificadas por rating, decrescente\n",
        "    df.sort_values(by=['Prediction','ItemId'],ascending=[False,True],inplace=True)\n",
        "    return df[['UserId','ItemId']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8W3G6qe-fdUi"
      },
      "outputs": [],
      "source": [
        "def predict(to_predict):\n",
        "    df_by_user={}\n",
        "    #cria um conjunto de dados para as previsões de cada usuário\n",
        "    for user, d in to_predict.groupby('UserId'):\n",
        "        df_by_user[user] = d\n",
        "\n",
        "    #prever para cada usuário\n",
        "    for user in df_by_user:\n",
        "        #coldstart\n",
        "        if not user in user_id_map:\n",
        "            df_by_user[user]=sort_by_features(df_by_user[user])\n",
        "        #not coldstart\n",
        "        else:\n",
        "            df_by_user[user]=sort_by_predictions(df_by_user[user])\n",
        "\n",
        "    #retornar previsões de user-item em userId crescente e ordem de rating decrescente\n",
        "    return pd.concat(list(df_by_user.values()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxGQuWH9fdUk"
      },
      "outputs": [],
      "source": [
        "df=predict(targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_pI091xfdUl"
      },
      "outputs": [],
      "source": [
        "#Arquivo final com as previsões\n",
        "with open ('/content/output.csv', 'w') as file:\n",
        "    file.write('UserId,ItemId\\n')\n",
        "    for prediction in df[['UserId','ItemId']].to_dict(orient='records'):\n",
        "        file.write(prediction['UserId']+','+prediction['ItemId']+'\\n')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}